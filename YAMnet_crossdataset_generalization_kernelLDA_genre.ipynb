{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import pickle\n",
    "import numpy.linalg as la\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn import svm\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embeddings and align classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irmas\n",
      "irmas/openl3\n",
      "irmas/openl3/features\n",
      "irmas/openl3/keys\n",
      "irmas/vggish\n",
      "irmas/vggish/features\n",
      "irmas/vggish/keys\n",
      "irmas/yamnet\n",
      "irmas/yamnet/features\n",
      "irmas/yamnet/keys\n",
      "openmic\n",
      "openmic/openl3\n",
      "openmic/openl3/features\n",
      "openmic/openl3/keys\n",
      "openmic/vggish\n",
      "openmic/vggish/features\n",
      "openmic/vggish/keys\n",
      "openmic/yamnet\n",
      "openmic/yamnet/features\n",
      "openmic/yamnet/keys\n"
     ]
    }
   ],
   "source": [
    "embeddings = h5py.File('../embedding-bias/embeddings.h5', 'r')\n",
    "\n",
    "def printname(name):\n",
    "    print(name)\n",
    "embeddings.visit(printname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cello': 3,\n",
       " 'clarinet': 4,\n",
       " 'flute': 7,\n",
       " 'guitar': 8,\n",
       " 'organ': 11,\n",
       " 'piano': 12,\n",
       " 'saxophone': 13,\n",
       " 'trumpet': 16,\n",
       " 'violin': 18,\n",
       " 'voice': 19}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('class-map-10.json', 'r') as f: # only consider 10 classes of Openmic dataset\n",
    "    class_map = json.load(f)\n",
    "    \n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a dict to align the classes between Openmic dataset (key) and Irmas dataset (val)\n",
    "class_align = {'cello': 'cel',\n",
    "               'clarinet': 'cla',\n",
    "               'flute': 'flu',\n",
    "               'guitar': ['gac', 'gel'],\n",
    "               'organ': 'org',\n",
    "               'piano': 'pia',\n",
    "               'saxophone': 'sax',\n",
    "               'trumpet': 'tru',\n",
    "               'violin': 'vio',\n",
    "               'voice': 'voi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a Pandas DataFrame to record all results and save into a csv file later\n",
    "result_all = pd.DataFrame({'instrument': [],\n",
    "                          'train_set': [],\n",
    "                          'test_set': [],\n",
    "                          'precision': [],\n",
    "                          'recall': [],\n",
    "                          'f1-score': [],\n",
    "                          'support': [],\n",
    "                          'accuracy': [],\n",
    "                          'roc_auc': [],\n",
    "                          'ap': []\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_name = 'yamnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irmas->irmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33525, 1024) (33525,)\n",
      "(6705,)\n"
     ]
    }
   ],
   "source": [
    "# irmas: Vggish embedding\n",
    "feature = np.array(embeddings['irmas'][embedding_name]['features'])\n",
    "keys_ori = np.array(embeddings['irmas'][embedding_name]['keys'])\n",
    "print(feature.shape, keys_ori.shape)\n",
    "\n",
    "key_clip = np.unique(keys_ori)\n",
    "print(key_clip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'001__[gel][dru][pop_roc]0829__1',\n",
       "       b'001__[gel][dru][pop_roc]0829__2',\n",
       "       b'001__[gel][dru][pop_roc]0829__3', ..., b'[voi][pop_roc]2548__1',\n",
       "       b'[voi][pop_roc]2548__2', b'[voi][pop_roc]2548__3'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ec2b61bde9464c9acf4d758aec255c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 1024) (6705,)\n"
     ]
    }
   ],
   "source": [
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys_ori[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "key_clip = np.array([str(k, encoding='utf-8') for k in key_clip])\n",
    "print(feature_clip.shape, key_clip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_train = list(pd.read_csv('irmas_train.csv', header=None, squeeze=True))\n",
    "key_test = list(pd.read_csv('irmas_test.csv', header=None, squeeze=True))\n",
    "\n",
    "# key_train = np.array([k[2:-1] for k in key_train])\n",
    "# key_test = np.array([k[2:-1]  for k in key_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these loops go through all sample keys, and save their row numbers to either idx_train or idx_test\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for k in range(len(key_clip)):\n",
    "    if str(key_clip[k]) in key_train:\n",
    "        idx_train.append(k)\n",
    "    elif str(key_clip[k]) in key_test:\n",
    "        idx_test.append(k)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(str(key_clip[k])))\n",
    "        \n",
    "# cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cello', 'clarinet', 'flute', 'guitar', 'organ', 'piano',\n",
       "       'saxophone', 'trumpet', 'violin', 'voice'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keys = np.array([str(k, encoding='utf-8') for k in key_clip])\n",
    "keys = np.array(key_clip)\n",
    "keys = [key[key.index('[')+1:key.index(']')] for key in keys]\n",
    "\n",
    "for key in class_align:\n",
    "    keys = [key if x in class_align[key] else x for x in keys]\n",
    "    \n",
    "keys = np.array(keys)\n",
    "np.unique(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 1024)\n",
      "(1666, 1024)\n"
     ]
    }
   ],
   "source": [
    "# use the split indices to partition the features, labels, and masks\n",
    "X_train = feature_clip[idx_train,:]\n",
    "X_test = feature_clip[idx_test]\n",
    "\n",
    "Y_true_train = keys[idx_train]\n",
    "Y_true_test = keys[idx_test]\n",
    "\n",
    "# print out the sliced shapes as a sanity check\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 4096) (1666, 4096)\n",
      "RBFSampler(gamma=1e-05, n_components=4096, random_state=0)\n",
      "(5, 4096) (5, 5) (5,) (5, 4096) (4096, 4096)\n",
      "(5039, 4096) (1666, 4096)\n"
     ]
    }
   ],
   "source": [
    "# standardize embedding\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# kernelize embedding\n",
    "feature_map_fourier = RBFSampler(n_components=4*X_train.shape[1], random_state=0)\n",
    "param_grid = {'gamma': [10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1)] }  \n",
    "scoring = 'roc_auc'; cv = 3\n",
    "Sampler = GridSearchCV(feature_map_fourier, param_grid=param_grid, cv=cv, scoring=scoring)  \n",
    "Sampler.fit(X_train)\n",
    "X_train = Sampler.transform(X_train)\n",
    "X_test = Sampler.transform(X_test)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print(Sampler.best_estimator_)\n",
    "\n",
    "############################# project the LDA direction #############################\n",
    "file = open('kernelize_LDA_' + embedding_name + '_coef_genre.pickle', 'rb')\n",
    "globals()['LDA_coef_' + embedding_name] = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "W = globals()['LDA_coef_' + embedding_name]\n",
    "U, s, V = la.svd(W, full_matrices=False)\n",
    "A = np.dot(V.T, V)\n",
    "print(W.shape, U.shape, s.shape, V.shape, A.shape)\n",
    "\n",
    "X_train = X_train.dot(np.eye(len(A)) - A)\n",
    "X_test = X_test.dot(np.eye(len(A)) - A)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "cello\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.93      0.96      1572\n",
      "        True       0.42      0.87      0.57        94\n",
      "\n",
      "    accuracy                           0.92      1666\n",
      "   macro avg       0.71      0.90      0.76      1666\n",
      "weighted avg       0.96      0.92      0.94      1666\n",
      "\n",
      "ROC-AUC = 0.963\t\tAP = 0.759\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.88      0.93      1539\n",
      "        True       0.37      0.86      0.52       127\n",
      "\n",
      "    accuracy                           0.88      1666\n",
      "   macro avg       0.68      0.87      0.72      1666\n",
      "weighted avg       0.94      0.88      0.90      1666\n",
      "\n",
      "ROC-AUC = 0.918\t\tAP = 0.684\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.88      0.93      1545\n",
      "        True       0.37      0.88      0.53       121\n",
      "\n",
      "    accuracy                           0.88      1666\n",
      "   macro avg       0.68      0.88      0.73      1666\n",
      "weighted avg       0.95      0.88      0.90      1666\n",
      "\n",
      "ROC-AUC = 0.941\t\tAP = 0.723\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.90      0.93      1320\n",
      "        True       0.70      0.89      0.78       346\n",
      "\n",
      "    accuracy                           0.90      1666\n",
      "   macro avg       0.84      0.90      0.86      1666\n",
      "weighted avg       0.91      0.90      0.90      1666\n",
      "\n",
      "ROC-AUC = 0.966\t\tAP = 0.895\n",
      "----------------------------------------------------\n",
      "organ\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.94      0.97      1492\n",
      "        True       0.64      0.95      0.77       174\n",
      "\n",
      "    accuracy                           0.94      1666\n",
      "   macro avg       0.82      0.94      0.87      1666\n",
      "weighted avg       0.96      0.94      0.94      1666\n",
      "\n",
      "ROC-AUC = 0.987\t\tAP = 0.886\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.97      1496\n",
      "        True       0.69      0.88      0.78       170\n",
      "\n",
      "    accuracy                           0.95      1666\n",
      "   macro avg       0.84      0.92      0.87      1666\n",
      "weighted avg       0.96      0.95      0.95      1666\n",
      "\n",
      "ROC-AUC = 0.976\t\tAP = 0.893\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.84      0.90      1516\n",
      "        True       0.32      0.77      0.46       150\n",
      "\n",
      "    accuracy                           0.83      1666\n",
      "   macro avg       0.65      0.80      0.68      1666\n",
      "weighted avg       0.91      0.83      0.86      1666\n",
      "\n",
      "ROC-AUC = 0.898\t\tAP = 0.521\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.92      0.95      1516\n",
      "        True       0.53      0.87      0.65       150\n",
      "\n",
      "    accuracy                           0.92      1666\n",
      "   macro avg       0.76      0.89      0.80      1666\n",
      "weighted avg       0.94      0.92      0.93      1666\n",
      "\n",
      "ROC-AUC = 0.964\t\tAP = 0.846\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.89      0.93      1523\n",
      "        True       0.39      0.78      0.52       143\n",
      "\n",
      "    accuracy                           0.88      1666\n",
      "   macro avg       0.68      0.83      0.72      1666\n",
      "weighted avg       0.93      0.88      0.89      1666\n",
      "\n",
      "ROC-AUC = 0.910\t\tAP = 0.679\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.97      0.98      1475\n",
      "        True       0.79      0.97      0.87       191\n",
      "\n",
      "    accuracy                           0.97      1666\n",
      "   macro avg       0.89      0.97      0.93      1666\n",
      "weighted avg       0.97      0.97      0.97      1666\n",
      "\n",
      "ROC-AUC = 0.993\t\tAP = 0.948\n"
     ]
    }
   ],
   "source": [
    "train_set_name, test_set_name = 'irmas', 'irmas'\n",
    "\n",
    "# use a dictionary to include the classifier for each instrument trained on the dataset based on the embedding\n",
    "globals()['models_'+train_set_name] = dict()  \n",
    "\n",
    "# iterate over all istrument classes, and fit a model for each one\n",
    "for instrument in class_align:\n",
    "    \n",
    "    # get the training and testing labels for each instrument\n",
    "    Y_true_train_inst = Y_true_train==instrument\n",
    "    Y_true_test_inst = Y_true_test==instrument\n",
    "    \n",
    "    # initialize and a logistic regression model\n",
    "    LRmodel = LogisticRegression(random_state=0, penalty='l2', solver='liblinear', class_weight='balanced')\n",
    "    \n",
    "    # hyperparameter tunning for logistic regression model\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100] }  \n",
    "    scoring = 'roc_auc'; cv = 3\n",
    "    clf =  GridSearchCV(LRmodel, param_grid=param_grid, cv=cv, scoring=scoring)  \n",
    "    \n",
    "    # fit the model\n",
    "    clf.fit(X_train, Y_true_train_inst)\n",
    "    \n",
    "    # predict\n",
    "    Y_pred_test_inst = clf.predict(X_test)\n",
    "    \n",
    "    # Get prediction scores for the positive class\n",
    "    Y_pred_test_scores = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # print result for each instrument\n",
    "    print('-' * 52); print(instrument); print('\\tTEST')\n",
    "    print(classification_report(Y_true_test_inst, Y_pred_test_inst))\n",
    "    \n",
    "    model_auc = roc_auc_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    model_ap = average_precision_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    print(f'ROC-AUC = {model_auc:.3f}\\t\\tAP = {model_ap:.3f}')\n",
    "    \n",
    "    # store the classifier in the model dictionary\n",
    "    globals()['models_'+train_set_name][instrument] = clf\n",
    "    \n",
    "    # record the result for each instrument\n",
    "    report = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['True']\n",
    "    report['roc_auc'] = model_auc\n",
    "    report['ap'] = model_ap\n",
    "    \n",
    "    report_accuracy = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['accuracy'][-2]\n",
    "    result_inst = [instrument, train_set_name, test_set_name, report['precision'], report['recall'],\n",
    "                   report['f1-score'], report['support'], report_accuracy, model_auc, model_ap]\n",
    "    result_all = result_all.append(pd.DataFrame(np.expand_dims(np.array(result_inst), axis=0), \n",
    "                                                columns=result_all.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openmic->openmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380000, 1024) (380000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openmic: vggish embedding\n",
    "feature = np.array(embeddings['openmic'][embedding_name]['features'])\n",
    "keys = np.array(embeddings['openmic'][embedding_name]['keys'])\n",
    "print(feature.shape, keys.shape)\n",
    "\n",
    "key_clip = np.unique(keys)\n",
    "key_clip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f44d6549d491eb625b797ab19cee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1024) (20000,)\n"
     ]
    }
   ],
   "source": [
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "print(feature_clip.shape, key_clip.shape)\n",
    "\n",
    "key_clip = np.array([str(k, encoding='utf-8') for k in key_clip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 20) (20000, 20) (20000,)\n"
     ]
    }
   ],
   "source": [
    "# key-label map using the information from the dataset source\n",
    "data_root = '../datasets/openmic-2018/'\n",
    "# Replaced the above by a local symbolic link within the github repo\n",
    "# data_root = 'openmic-2018/'\n",
    "\n",
    "np_load_old = np.load   # save np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True,**k)   # modify the default parameters of np.load\n",
    "\n",
    "Ytrue = np.load(os.path.join(data_root, 'openmic-2018.npz'))['Y_true']\n",
    "Ymask = np.load(os.path.join(data_root, 'openmic-2018.npz'))['Y_mask']\n",
    "sample_key = np.load(os.path.join(data_root, 'openmic-2018.npz'))['sample_key']\n",
    "\n",
    "np.load = np_load_old   # restore np.load for future normal usage\n",
    "del(np_load_old)\n",
    "\n",
    "print(Ytrue.shape, Ymask.shape, sample_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd591fa6b074bf8ab393e26dca992f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1024) (20000, 20) (20000, 20)\n"
     ]
    }
   ],
   "source": [
    "Y_true = []\n",
    "Y_mask = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    Y_true.append(Ytrue[sample_key==key])\n",
    "    Y_mask.append(Ymask[sample_key==key])\n",
    "    \n",
    "Y_true = np.squeeze(np.array(Y_true))\n",
    "Y_mask = np.squeeze(np.array(Y_mask))\n",
    "\n",
    "X = feature_clip\n",
    "del(feature_clip)\n",
    "\n",
    "print(X.shape, Y_true.shape, Y_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "split_train = pd.read_csv('openmic2018_train.csv', header=None, squeeze=True)\n",
    "split_test = pd.read_csv('openmic2018_test.csv', header=None, squeeze=True)\n",
    "\n",
    "print('# Train: {},  # Test: {}'.format(len(split_train), len(split_test)))\n",
    "\n",
    "train_set = set(split_train)\n",
    "test_set = set(split_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(key_clip):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[n]))\n",
    "        \n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 1024)\n",
      "(5085, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "\n",
    "Y_true_train = Y_true[idx_train]\n",
    "Y_true_test = Y_true[idx_test]\n",
    "\n",
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_test = Y_mask[idx_test]\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 4096) (5085, 4096)\n",
      "RBFSampler(gamma=1e-05, n_components=4096, random_state=0)\n",
      "(14915, 4096) (5085, 4096)\n"
     ]
    }
   ],
   "source": [
    "# standardize embedding\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# kernelize embedding\n",
    "feature_map_fourier = RBFSampler(n_components=4*X_train.shape[1], random_state=0)\n",
    "param_grid = {'gamma': [10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1)] }  \n",
    "scoring = 'roc_auc'; cv = 3\n",
    "Sampler = GridSearchCV(feature_map_fourier, param_grid=param_grid, cv=cv, scoring=scoring)  \n",
    "Sampler.fit(X_train)\n",
    "X_train = Sampler.transform(X_train)\n",
    "X_test = Sampler.transform(X_test)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print(Sampler.best_estimator_)\n",
    "\n",
    "X_train = X_train.dot(np.eye(len(A)) - A)\n",
    "X_test = X_test.dot(np.eye(len(A)) - A)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "cello\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.83      0.84       259\n",
      "        True       0.81      0.83      0.82       226\n",
      "\n",
      "    accuracy                           0.83       485\n",
      "   macro avg       0.83      0.83      0.83       485\n",
      "weighted avg       0.83      0.83      0.83       485\n",
      "\n",
      "ROC-AUC = 0.912\t\tAP = 0.888\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.64      0.75       503\n",
      "        True       0.37      0.76      0.49       137\n",
      "\n",
      "    accuracy                           0.67       640\n",
      "   macro avg       0.64      0.70      0.62       640\n",
      "weighted avg       0.79      0.67      0.70       640\n",
      "\n",
      "ROC-AUC = 0.767\t\tAP = 0.449\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.67      0.76       387\n",
      "        True       0.52      0.78      0.62       175\n",
      "\n",
      "    accuracy                           0.71       562\n",
      "   macro avg       0.70      0.73      0.69       562\n",
      "weighted avg       0.76      0.71      0.72       562\n",
      "\n",
      "ROC-AUC = 0.819\t\tAP = 0.707\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.99      0.95       150\n",
      "        True       0.99      0.95      0.97       286\n",
      "\n",
      "    accuracy                           0.97       436\n",
      "   macro avg       0.96      0.97      0.96       436\n",
      "weighted avg       0.97      0.97      0.97       436\n",
      "\n",
      "ROC-AUC = 0.992\t\tAP = 0.996\n",
      "----------------------------------------------------\n",
      "organ\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.80      0.82       310\n",
      "        True       0.55      0.63      0.59       121\n",
      "\n",
      "    accuracy                           0.75       431\n",
      "   macro avg       0.70      0.71      0.70       431\n",
      "weighted avg       0.76      0.75      0.76       431\n",
      "\n",
      "ROC-AUC = 0.828\t\tAP = 0.634\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.88      0.91       130\n",
      "        True       0.95      0.98      0.96       285\n",
      "\n",
      "    accuracy                           0.94       415\n",
      "   macro avg       0.94      0.93      0.93       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "ROC-AUC = 0.985\t\tAP = 0.993\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.82      0.84       324\n",
      "        True       0.82      0.85      0.83       305\n",
      "\n",
      "    accuracy                           0.83       629\n",
      "   macro avg       0.83      0.83      0.83       629\n",
      "weighted avg       0.83      0.83      0.83       629\n",
      "\n",
      "ROC-AUC = 0.915\t\tAP = 0.905\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.81      0.82       467\n",
      "        True       0.73      0.75      0.74       318\n",
      "\n",
      "    accuracy                           0.79       785\n",
      "   macro avg       0.78      0.78      0.78       785\n",
      "weighted avg       0.79      0.79      0.79       785\n",
      "\n",
      "ROC-AUC = 0.874\t\tAP = 0.834\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.86      0.82       237\n",
      "        True       0.91      0.86      0.88       394\n",
      "\n",
      "    accuracy                           0.86       631\n",
      "   macro avg       0.85      0.86      0.85       631\n",
      "weighted avg       0.86      0.86      0.86       631\n",
      "\n",
      "ROC-AUC = 0.936\t\tAP = 0.954\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.93      0.90       150\n",
      "        True       0.95      0.92      0.93       224\n",
      "\n",
      "    accuracy                           0.92       374\n",
      "   macro avg       0.91      0.92      0.92       374\n",
      "weighted avg       0.92      0.92      0.92       374\n",
      "\n",
      "ROC-AUC = 0.977\t\tAP = 0.986\n"
     ]
    }
   ],
   "source": [
    "# This part of the code follows the baseline model for instrument recognition on the openmic dataset:\n",
    "# https://github.com/cosmir/openmic-2018/blob/master/examples/modeling-baseline.ipynb\n",
    "train_set_name, test_set_name = 'openmic', 'openmic'\n",
    "\n",
    "# use a dictionary to include the classifier for each instrument trained on the dataset based on the embedding\n",
    "globals()['models_'+train_set_name] = dict()  \n",
    "\n",
    "# We'll iterate over all istrument classes, and fit a model for each one\n",
    "# After training, we'll print a classification report for each instrument\n",
    "for instrument in class_align:\n",
    "    \n",
    "    # Map the instrument name to its column number\n",
    "    inst_num = class_map[instrument]\n",
    "    \n",
    "    # First, sub-sample the data: we need to select down to the data for which we have annotations\n",
    "    # This is what the mask arrays are for\n",
    "    train_inst = Y_mask_train[:, inst_num]\n",
    "    test_inst = Y_mask_test[:, inst_num]\n",
    "    \n",
    "    # Here, we're using the Y_mask_train array to slice out only the training examples\n",
    "    # for which we have annotations for the given class\n",
    "    X_train_inst = X_train[train_inst]\n",
    "    \n",
    "    # Again, we slice the labels to the annotated examples\n",
    "    # We thresold the label likelihoods at 0.5 to get binary labels\n",
    "    Y_true_train_inst = Y_true_train[train_inst, inst_num] >= 0.5\n",
    "    \n",
    "    # Repeat the above slicing and dicing but for the test set\n",
    "    X_test_inst = X_test[test_inst]\n",
    "    Y_true_test_inst = Y_true_test[test_inst, inst_num] >= 0.5\n",
    "\n",
    "    # initialize and a logistic regression model\n",
    "    LRmodel = LogisticRegression(random_state=0, penalty='l2', solver='liblinear', class_weight='balanced')\n",
    "    \n",
    "    # hyperparameter tunning for logistic regression model\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100] }  \n",
    "    scoring = 'roc_auc'; cv = 3\n",
    "    clf =  GridSearchCV(LRmodel, param_grid=param_grid, cv=cv, scoring=scoring)    \n",
    "    \n",
    "    # fit the model\n",
    "    clf.fit(X_train_inst, Y_true_train_inst)\n",
    "\n",
    "    # predict\n",
    "    Y_pred_test_inst = clf.predict(X_test_inst)\n",
    "    # Get prediction scores for the positive class\n",
    "    Y_pred_test_scores = clf.predict_proba(X_test_inst)[:, 1]\n",
    "    \n",
    "    # print result for each instrument\n",
    "    print('-' * 52); print(instrument); print('\\tTEST')\n",
    "    print(classification_report(Y_true_test_inst, Y_pred_test_inst))\n",
    "    \n",
    "    model_auc = roc_auc_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    model_ap = average_precision_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    print(f'ROC-AUC = {model_auc:.3f}\\t\\tAP = {model_ap:.3f}')\n",
    "    \n",
    "    # store the classifier in the model dictionary\n",
    "    globals()['models_'+train_set_name][instrument] = clf\n",
    "    \n",
    "    # record the result for each instrument\n",
    "    report = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['True']\n",
    "    report['roc_auc'] = model_auc\n",
    "    report['ap'] = model_ap\n",
    "    report_accuracy = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['accuracy'][-2]\n",
    "    result_inst = [instrument, train_set_name, test_set_name, report['precision'], report['recall'],\n",
    "                   report['f1-score'], report['support'], report_accuracy, model_auc, model_ap]   \n",
    "    result_all = result_all.append(pd.DataFrame(np.expand_dims(np.array(result_inst), axis=0), \n",
    "                                                columns=result_all.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irmas->openmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "cello\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.72      0.73       259\n",
      "        True       0.69      0.71      0.70       226\n",
      "\n",
      "    accuracy                           0.72       485\n",
      "   macro avg       0.71      0.71      0.71       485\n",
      "weighted avg       0.72      0.72      0.72       485\n",
      "\n",
      "ROC-AUC = 0.803\t\tAP = 0.772\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.71      0.78       503\n",
      "        True       0.35      0.56      0.43       137\n",
      "\n",
      "    accuracy                           0.68       640\n",
      "   macro avg       0.60      0.64      0.60       640\n",
      "weighted avg       0.75      0.68      0.70       640\n",
      "\n",
      "ROC-AUC = 0.689\t\tAP = 0.384\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.60      0.70       387\n",
      "        True       0.46      0.75      0.57       175\n",
      "\n",
      "    accuracy                           0.65       562\n",
      "   macro avg       0.65      0.68      0.64       562\n",
      "weighted avg       0.72      0.65      0.66       562\n",
      "\n",
      "ROC-AUC = 0.732\t\tAP = 0.609\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.97      0.90       150\n",
      "        True       0.98      0.90      0.94       286\n",
      "\n",
      "    accuracy                           0.92       436\n",
      "   macro avg       0.91      0.94      0.92       436\n",
      "weighted avg       0.93      0.92      0.93       436\n",
      "\n",
      "ROC-AUC = 0.981\t\tAP = 0.992\n",
      "----------------------------------------------------\n",
      "organ\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.75      0.78       310\n",
      "        True       0.47      0.58      0.52       121\n",
      "\n",
      "    accuracy                           0.70       431\n",
      "   macro avg       0.65      0.66      0.65       431\n",
      "weighted avg       0.72      0.70      0.71       431\n",
      "\n",
      "ROC-AUC = 0.735\t\tAP = 0.557\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.94      0.85       130\n",
      "        True       0.97      0.87      0.92       285\n",
      "\n",
      "    accuracy                           0.89       415\n",
      "   macro avg       0.87      0.91      0.88       415\n",
      "weighted avg       0.91      0.89      0.90       415\n",
      "\n",
      "ROC-AUC = 0.964\t\tAP = 0.984\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.74      0.77       324\n",
      "        True       0.75      0.81      0.77       305\n",
      "\n",
      "    accuracy                           0.77       629\n",
      "   macro avg       0.77      0.77      0.77       629\n",
      "weighted avg       0.77      0.77      0.77       629\n",
      "\n",
      "ROC-AUC = 0.851\t\tAP = 0.832\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.78      0.77       467\n",
      "        True       0.67      0.65      0.66       318\n",
      "\n",
      "    accuracy                           0.73       785\n",
      "   macro avg       0.72      0.71      0.71       785\n",
      "weighted avg       0.73      0.73      0.73       785\n",
      "\n",
      "ROC-AUC = 0.790\t\tAP = 0.724\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.85      0.78       237\n",
      "        True       0.90      0.80      0.84       394\n",
      "\n",
      "    accuracy                           0.82       631\n",
      "   macro avg       0.81      0.82      0.81       631\n",
      "weighted avg       0.83      0.82      0.82       631\n",
      "\n",
      "ROC-AUC = 0.873\t\tAP = 0.920\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.95      0.89       150\n",
      "        True       0.97      0.87      0.91       224\n",
      "\n",
      "    accuracy                           0.90       374\n",
      "   macro avg       0.90      0.91      0.90       374\n",
      "weighted avg       0.91      0.90      0.90       374\n",
      "\n",
      "ROC-AUC = 0.976\t\tAP = 0.985\n"
     ]
    }
   ],
   "source": [
    "train_set_name, test_set_name = 'irmas', 'openmic' \n",
    "\n",
    "# iterate over all istrument classes, and fit a model for each one\n",
    "for instrument in class_align:\n",
    "    \n",
    "    # Map the instrument name to its column number\n",
    "    inst_num = class_map[instrument]\n",
    "    \n",
    "    # First, sub-sample the data: we need to select down to the data for which we have annotations \n",
    "    # This is what the mask arrays are for\n",
    "    test_inst = Y_mask_test[:, inst_num]\n",
    "\n",
    "    # Repeat the above slicing and dicing but for the test set\n",
    "    X_test_inst = X_test[test_inst]\n",
    "    Y_true_test_inst = Y_true_test[test_inst, inst_num] >= 0.5\n",
    "\n",
    "    # evaluate the classifier \n",
    "    Y_pred_test_inst =  globals()['models_'+train_set_name][instrument].predict(X_test_inst)\n",
    "    Y_pred_test_scores =  globals()['models_'+train_set_name][instrument].predict_proba(X_test_inst)[:, 1]\n",
    "\n",
    "    # print result for each instrument\n",
    "    print('-' * 52); print(instrument); print('\\tTEST')\n",
    "    print(classification_report(Y_true_test_inst, Y_pred_test_inst))\n",
    "    \n",
    "    model_auc = roc_auc_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    model_ap = average_precision_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    print(f'ROC-AUC = {model_auc:.3f}\\t\\tAP = {model_ap:.3f}')\n",
    "    \n",
    "    # record the result for each instrument\n",
    "    report = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['True']\n",
    "    report['roc_auc'] = model_auc\n",
    "    report['ap'] = model_ap\n",
    "    report_accuracy = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['accuracy'][-2]\n",
    "    result_inst = [instrument, train_set_name, test_set_name, report['precision'], report['recall'],\n",
    "                   report['f1-score'], report['support'], report_accuracy, model_auc, model_ap]   \n",
    "    result_all = result_all.append(pd.DataFrame(np.expand_dims(np.array(result_inst), axis=0), \n",
    "                                                columns=result_all.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openmic->irmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33525, 1024) (33525,)\n",
      "(6705,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a677171e33843f6912ac228679ae7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 1024) (6705,)\n"
     ]
    }
   ],
   "source": [
    "# irmas: vggish embedding\n",
    "feature = np.array(embeddings['irmas'][embedding_name]['features'])\n",
    "keys_ori = np.array(embeddings['irmas'][embedding_name]['keys'])\n",
    "print(feature.shape, keys_ori.shape)\n",
    "\n",
    "key_clip = np.unique(keys_ori)\n",
    "print(key_clip.shape)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys_ori[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "key_clip = np.array([str(k, encoding='utf-8') for k in key_clip])\n",
    "print(feature_clip.shape, key_clip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_train = list(pd.read_csv('irmas_train.csv', header=None, squeeze=True))\n",
    "key_test = list(pd.read_csv('irmas_test.csv', header=None, squeeze=True))\n",
    "\n",
    "# key_train = np.array([k[2:-1] for k in key_train])\n",
    "# key_test = np.array([k[2:-1]  for k in key_test])\n",
    "\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for k in range(len(key_clip)):\n",
    "    if str(key_clip[k]) in key_train:\n",
    "        idx_train.append(k)\n",
    "    elif str(key_clip[k]) in key_test:\n",
    "        idx_test.append(k)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[k]))\n",
    "        \n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cello', 'clarinet', 'flute', 'guitar', 'organ', 'piano',\n",
       "       'saxophone', 'trumpet', 'violin', 'voice'], dtype='<U9')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keys = np.array([str(k, 'utf-8') for k in key_clip])\n",
    "keys = np.array(key_clip)\n",
    "keys = [key[key.index('[')+1:key.index(']')] for key in keys]\n",
    "\n",
    "for key in class_align:\n",
    "    keys = [key if x in class_align[key] else x for x in keys]\n",
    "    \n",
    "keys = np.array(keys)\n",
    "np.unique(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 1024)\n",
      "(1666, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = feature_clip[idx_train,:]\n",
    "X_test = feature_clip[idx_test]\n",
    "\n",
    "Y_true_train = keys[idx_train]\n",
    "Y_true_test = keys[idx_test]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 4096) (1666, 4096)\n",
      "RBFSampler(gamma=1e-05, n_components=4096, random_state=0)\n",
      "(5039, 4096) (1666, 4096)\n"
     ]
    }
   ],
   "source": [
    "# standardize embedding\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# kernelize embedding\n",
    "feature_map_fourier = RBFSampler(n_components=4*X_train.shape[1], random_state=0)\n",
    "param_grid = {'gamma': [10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1)] }  \n",
    "scoring = 'roc_auc'; cv = 3\n",
    "Sampler = GridSearchCV(feature_map_fourier, param_grid=param_grid, cv=cv, scoring=scoring)  \n",
    "Sampler.fit(X_train)\n",
    "X_train = Sampler.transform(X_train)\n",
    "X_test = Sampler.transform(X_test)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print(Sampler.best_estimator_)\n",
    "\n",
    "X_train = X_train.dot(np.eye(len(A)) - A)\n",
    "X_test = X_test.dot(np.eye(len(A)) - A)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "cello\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.86      0.92      1572\n",
      "        True       0.26      0.79      0.39        94\n",
      "\n",
      "    accuracy                           0.86      1666\n",
      "   macro avg       0.62      0.83      0.65      1666\n",
      "weighted avg       0.94      0.86      0.89      1666\n",
      "\n",
      "ROC-AUC = 0.887\t\tAP = 0.603\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.89      0.93      1539\n",
      "        True       0.35      0.72      0.47       127\n",
      "\n",
      "    accuracy                           0.88      1666\n",
      "   macro avg       0.66      0.81      0.70      1666\n",
      "weighted avg       0.93      0.88      0.90      1666\n",
      "\n",
      "ROC-AUC = 0.880\t\tAP = 0.595\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.77      0.86      1545\n",
      "        True       0.22      0.82      0.34       121\n",
      "\n",
      "    accuracy                           0.77      1666\n",
      "   macro avg       0.60      0.79      0.60      1666\n",
      "weighted avg       0.93      0.77      0.82      1666\n",
      "\n",
      "ROC-AUC = 0.852\t\tAP = 0.525\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.86      0.89      1320\n",
      "        True       0.57      0.73      0.64       346\n",
      "\n",
      "    accuracy                           0.83      1666\n",
      "   macro avg       0.75      0.79      0.76      1666\n",
      "weighted avg       0.85      0.83      0.84      1666\n",
      "\n",
      "ROC-AUC = 0.894\t\tAP = 0.714\n",
      "----------------------------------------------------\n",
      "organ\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.92      0.92      1492\n",
      "        True       0.22      0.18      0.20       174\n",
      "\n",
      "    accuracy                           0.85      1666\n",
      "   macro avg       0.56      0.55      0.56      1666\n",
      "weighted avg       0.83      0.85      0.84      1666\n",
      "\n",
      "ROC-AUC = 0.553\t\tAP = 0.163\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.78      0.86      1496\n",
      "        True       0.26      0.69      0.38       170\n",
      "\n",
      "    accuracy                           0.77      1666\n",
      "   macro avg       0.61      0.74      0.62      1666\n",
      "weighted avg       0.89      0.77      0.81      1666\n",
      "\n",
      "ROC-AUC = 0.841\t\tAP = 0.604\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.83      0.89      1516\n",
      "        True       0.26      0.63      0.37       150\n",
      "\n",
      "    accuracy                           0.81      1666\n",
      "   macro avg       0.61      0.73      0.63      1666\n",
      "weighted avg       0.89      0.81      0.84      1666\n",
      "\n",
      "ROC-AUC = 0.817\t\tAP = 0.347\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.88      0.92      1516\n",
      "        True       0.38      0.76      0.51       150\n",
      "\n",
      "    accuracy                           0.87      1666\n",
      "   macro avg       0.68      0.82      0.72      1666\n",
      "weighted avg       0.92      0.87      0.89      1666\n",
      "\n",
      "ROC-AUC = 0.899\t\tAP = 0.577\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.85      0.91      1523\n",
      "        True       0.30      0.66      0.41       143\n",
      "\n",
      "    accuracy                           0.84      1666\n",
      "   macro avg       0.63      0.76      0.66      1666\n",
      "weighted avg       0.91      0.84      0.86      1666\n",
      "\n",
      "ROC-AUC = 0.828\t\tAP = 0.385\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.91      0.95      1475\n",
      "        True       0.59      0.98      0.73       191\n",
      "\n",
      "    accuracy                           0.92      1666\n",
      "   macro avg       0.79      0.95      0.84      1666\n",
      "weighted avg       0.95      0.92      0.93      1666\n",
      "\n",
      "ROC-AUC = 0.986\t\tAP = 0.919\n"
     ]
    }
   ],
   "source": [
    "train_set_name, test_set_name = 'openmic', 'irmas' \n",
    "\n",
    "# iterate over all istrument classes, and fit a model for each one\n",
    "for instrument in class_align:\n",
    "    \n",
    "    # get the training and testing labels for each instrument\n",
    "    Y_true_test_inst = Y_true_test==instrument\n",
    "\n",
    "    # evaluate the classifier\n",
    "    Y_pred_test_inst =  globals()['models_'+train_set_name][instrument].predict(X_test)\n",
    "    Y_pred_test_scores =  globals()['models_'+train_set_name][instrument].predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # print result for each instrument\n",
    "    print('-' * 52); print(instrument); print('\\tTEST')\n",
    "    print(classification_report(Y_true_test_inst, Y_pred_test_inst))\n",
    "    \n",
    "    model_auc = roc_auc_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    model_ap = average_precision_score(Y_true_test_inst, Y_pred_test_scores)\n",
    "    print(f'ROC-AUC = {model_auc:.3f}\\t\\tAP = {model_ap:.3f}')\n",
    "    \n",
    "    # record the result for each instrument\n",
    "    report = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['True']\n",
    "    report['roc_auc'] = model_auc\n",
    "    report['ap'] = model_ap\n",
    "    report_accuracy = pd.DataFrame(classification_report(Y_true_test_inst, Y_pred_test_inst, output_dict=True))['accuracy'][-2]\n",
    "    result_inst = [instrument, train_set_name, test_set_name, report['precision'], report['recall'],\n",
    "                   report['f1-score'], report['support'], report_accuracy, model_auc, model_ap]   \n",
    "    result_all = result_all.append(pd.DataFrame(np.expand_dims(np.array(result_inst), axis=0), \n",
    "                                                columns=result_all.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot result on each instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all result into a csv file\n",
    "result_all.to_csv('YAMnet_crossdataset_result_kernelLDA_genre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF and accuracy of Vggish averaged over all instruments for each case:\n",
      "openmic->openmic:[0.76, 0.83, 0.78, 0.83, 0.9, 0.83]\n",
      "irmas->openmic:[0.72, 0.75, 0.73, 0.78, 0.84, 0.78]\n",
      "irmas->irmas:[0.52, 0.87, 0.64, 0.91, 0.95, 0.78]\n",
      "openmic->irmas:[0.34, 0.7, 0.45, 0.84, 0.84, 0.54]\n"
     ]
    }
   ],
   "source": [
    "# check the PRF averaged over all instruments for each case:\n",
    "\n",
    "train_irmas = result_all[result_all['train_set']=='irmas']\n",
    "train_openmic = result_all[result_all['train_set']=='openmic']\n",
    "\n",
    "irmas_irmas = train_irmas[train_irmas['test_set']=='irmas']\n",
    "irmas_openmic = train_irmas[train_irmas['test_set']=='openmic']\n",
    "openmic_openmic = train_openmic[train_openmic['test_set']=='openmic']\n",
    "openmic_irmas = train_openmic[train_openmic['test_set']=='irmas']\n",
    "\n",
    "print('PRF and accuracy of Vggish averaged over all instruments for each case:')\n",
    "print('openmic->openmic:{}'.format(list(openmic_openmic[['precision', 'recall', 'f1-score', 'accuracy', 'roc_auc', 'ap']].astype(float).mean(axis=0).round(2))))\n",
    "print('irmas->openmic:{}'.format(list(irmas_openmic[['precision', 'recall', 'f1-score', 'accuracy', 'roc_auc', 'ap']].astype(float).mean(axis=0).round(2))))\n",
    "print('irmas->irmas:{}'.format(list(irmas_irmas[['precision', 'recall', 'f1-score', 'accuracy', 'roc_auc', 'ap']].astype(float).mean(axis=0).round(2))))\n",
    "print('openmic->irmas:{}'.format(list(openmic_irmas[['precision', 'recall', 'f1-score', 'accuracy', 'roc_auc', 'ap']].astype(float).mean(axis=0).round(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result of VGGish, yamnet, and OpenL3 into one csv file\n",
    "\n",
    "vggish = pd.read_csv('VGGish_crossdataset_result_kernelize.csv')\n",
    "openl3 = pd.read_csv('OpenL3_crossdataset_result_kernelize.csv')\n",
    "yamnet = pd.read_csv('YAMnet_crossdataset_result_kernelize.csv')\n",
    "\n",
    "# add embedding information, concatenate result\n",
    "vggish['embedding'] = ['vggish'] * len(vggish['instrument'])\n",
    "openl3['embedding'] = ['openl3'] * len(openl3['instrument'])\n",
    "yamnet['embedding'] = ['yamnet'] * len(openl3['instrument'])\n",
    "\n",
    "result_all_conca = pd.concat([vggish, openl3, yamnet], ignore_index=True)\n",
    "\n",
    "# move embedding to the first column\n",
    "cols = ['embedding', 'instrument', 'train_set', 'test_set', 'precision', 'recall', 'f1-score', 'support', 'accuracy', 'roc_auc', 'ap']\n",
    "result_all_conca =result_all_conca[cols]\n",
    "\n",
    "result_all_conca.to_csv('crossdataset_generalization_result_kernelize.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result of VGGish, yamnet, and OpenL3 into one csv file\n",
    "\n",
    "vggish = pd.read_csv('VGGish_crossdataset_result_kernelLDA.csv')\n",
    "openl3 = pd.read_csv('OpenL3_crossdataset_result_kernelLDA.csv')\n",
    "yamnet = pd.read_csv('YAMnet_crossdataset_result_kernelLDA.csv')\n",
    "\n",
    "# add embedding information, concatenate result\n",
    "vggish['embedding'] = ['vggish'] * len(vggish['instrument'])\n",
    "openl3['embedding'] = ['openl3'] * len(openl3['instrument'])\n",
    "yamnet['embedding'] = ['yamnet'] * len(openl3['instrument'])\n",
    "\n",
    "result_all_conca = pd.concat([vggish, openl3, yamnet], ignore_index=True)\n",
    "\n",
    "# move embedding to the first column\n",
    "cols = ['embedding', 'instrument', 'train_set', 'test_set', 'precision', 'recall', 'f1-score', 'support', 'accuracy', 'roc_auc', 'ap']\n",
    "result_all_conca =result_all_conca[cols]\n",
    "\n",
    "result_all_conca.to_csv('crossdataset_generalization_result_kernelLDA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result of VGGish, yamnet, and OpenL3 into one csv file\n",
    "\n",
    "vggish = pd.read_csv('VGGish_crossdataset_result_kernelLDA_genre.csv')\n",
    "openl3 = pd.read_csv('OpenL3_crossdataset_result_kernelLDA_genre.csv')\n",
    "yamnet = pd.read_csv('YAMnet_crossdataset_result_kernelLDA_genre.csv')\n",
    "\n",
    "# add embedding information, concatenate result\n",
    "vggish['embedding'] = ['vggish'] * len(vggish['instrument'])\n",
    "openl3['embedding'] = ['openl3'] * len(openl3['instrument'])\n",
    "yamnet['embedding'] = ['yamnet'] * len(openl3['instrument'])\n",
    "\n",
    "result_all_conca = pd.concat([vggish, openl3, yamnet], ignore_index=True)\n",
    "\n",
    "# move embedding to the first column\n",
    "cols = ['embedding', 'instrument', 'train_set', 'test_set', 'precision', 'recall', 'f1-score', 'support', 'accuracy', 'roc_auc', 'ap']\n",
    "result_all_conca =result_all_conca[cols]\n",
    "\n",
    "result_all_conca.to_csv('crossdataset_generalization_result_kernelLDA_genre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('crossdataset_generalization_result_kernelize.csv')\n",
    "df2 = pd.read_csv('crossdataset_generalization_result_kernelLDA.csv')\n",
    "df3 = pd.read_csv('crossdataset_generalization_result_kernelLDA_genre.csv')\n",
    "df1['embedding'] = ['vggish-k'] * 40 + ['openl3-k'] * 40 + ['yamnet-k'] * 40 \n",
    "df2['embedding'] = ['vggish-klda'] * 40 + ['openl3-klda'] * 40 + ['yamnet-klda'] * 40 \n",
    "df3['embedding'] = ['vggish-klda-genre'] * 40 + ['openl3-klda-genre'] * 40 + ['yamnet-klda-genre'] * 40\n",
    "\n",
    "df = df1.append(df2).append(df3)\n",
    "df.to_csv('crossdataset_generalization_result_allcompare.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_theme(context='notebook', style='whitegrid', palette='deep')\n",
    "# diverging_colors = sns.color_palette(\"GnBu\", 3) + sns.color_palette(\"flare\", 3) + \\\n",
    "#                    sns.color_palette(\"ch:s=.25,rot=-.25\", 3) \n",
    "# hue_order=['vggish-k', 'vggish-klda', 'vggish-klda-genre', 'openl3-k', 'openl3-klda', 'openl3-klda-genre',\n",
    "#           'yamnet-k', 'yamnet-klda', 'yamnet-klda-genre']\n",
    "\n",
    "# sns.catplot(data=df, row='train_set', col='test_set', y='instrument', x='roc_auc', hue='embedding', kind='bar', \n",
    "#             hue_order=hue_order, palette=diverging_colors);\n",
    "\n",
    "# plt.savefig('crossdataset_generalization_auc_kernelLDA_genre.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_theme(context='notebook', style='whitegrid')\n",
    "# diverging_colors = sns.color_palette(\"GnBu\", 3) + sns.color_palette(\"flare\", 3) + \\\n",
    "#                    sns.color_palette(\"ch:s=.25,rot=-.25\", 3) \n",
    "# hue_order=['vggish-k', 'vggish-klda', 'vggish-klda-genre', 'openl3-k', 'openl3-klda', 'openl3-klda-genre',\n",
    "#           'yamnet-k', 'yamnet-klda', 'yamnet-klda-genre']\n",
    "\n",
    "# sns.catplot(data=df, row='train_set', col='test_set', y='instrument', x='ap', hue='embedding', kind='bar', \n",
    "#             hue_order=hue_order, palette=diverging_colors);\n",
    "\n",
    "# plt.savefig('crossdataset_generalization_ap_kernelLDA_genre.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>instrument</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vggish</td>\n",
       "      <td>cello</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.924896</td>\n",
       "      <td>0.623731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vggish</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.434590</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.879935</td>\n",
       "      <td>0.534471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vggish</td>\n",
       "      <td>flute</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.309764</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.859544</td>\n",
       "      <td>0.891979</td>\n",
       "      <td>0.612665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vggish</td>\n",
       "      <td>guitar</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.662005</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.934091</td>\n",
       "      <td>0.825266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vggish</td>\n",
       "      <td>organ</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.647303</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.956881</td>\n",
       "      <td>0.706318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>yamnet-lda-genre</td>\n",
       "      <td>piano</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.226446</td>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.353548</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.699280</td>\n",
       "      <td>0.845085</td>\n",
       "      <td>0.575497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>yamnet-lda-genre</td>\n",
       "      <td>saxophone</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.205769</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.319403</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.726291</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.329186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>yamnet-lda-genre</td>\n",
       "      <td>trumpet</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.259188</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.401799</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.911381</td>\n",
       "      <td>0.662541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>yamnet-lda-genre</td>\n",
       "      <td>violin</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.210721</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.726291</td>\n",
       "      <td>0.839726</td>\n",
       "      <td>0.393855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>yamnet-lda-genre</td>\n",
       "      <td>voice</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.378758</td>\n",
       "      <td>0.989529</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.812725</td>\n",
       "      <td>0.982423</td>\n",
       "      <td>0.889406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            embedding instrument train_set test_set  precision    recall  \\\n",
       "0              vggish      cello     irmas    irmas   0.296296  0.851064   \n",
       "1              vggish   clarinet     irmas    irmas   0.302469  0.771654   \n",
       "2              vggish      flute     irmas    irmas   0.309764  0.760331   \n",
       "3              vggish     guitar     irmas    irmas   0.662005  0.820809   \n",
       "4              vggish      organ     irmas    irmas   0.506494  0.896552   \n",
       "..                ...        ...       ...      ...        ...       ...   \n",
       "115  yamnet-lda-genre      piano   openmic    irmas   0.226446  0.805882   \n",
       "116  yamnet-lda-genre  saxophone   openmic    irmas   0.205769  0.713333   \n",
       "117  yamnet-lda-genre    trumpet   openmic    irmas   0.259188  0.893333   \n",
       "118  yamnet-lda-genre     violin   openmic    irmas   0.210721  0.797203   \n",
       "119  yamnet-lda-genre      voice   openmic    irmas   0.378758  0.989529   \n",
       "\n",
       "     f1-score  support  accuracy   roc_auc        ap  \n",
       "0    0.439560     94.0  0.877551  0.924896  0.623731  \n",
       "1    0.434590    127.0  0.846939  0.879935  0.534471  \n",
       "2    0.440191    121.0  0.859544  0.891979  0.612665  \n",
       "3    0.732903    346.0  0.875750  0.934091  0.825266  \n",
       "4    0.647303    174.0  0.897959  0.956881  0.706318  \n",
       "..        ...      ...       ...       ...       ...  \n",
       "115  0.353548    170.0  0.699280  0.845085  0.575497  \n",
       "116  0.319403    150.0  0.726291  0.807256  0.329186  \n",
       "117  0.401799    150.0  0.760504  0.911381  0.662541  \n",
       "118  0.333333    143.0  0.726291  0.839726  0.393855  \n",
       "119  0.547826    191.0  0.812725  0.982423  0.889406  \n",
       "\n",
       "[360 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('crossdataset_generalization_result.csv')\n",
    "df2 = pd.read_csv('crossdataset_generalization_result_LDAproj.csv')\n",
    "df3 = pd.read_csv('crossdataset_generalization_result_LDAproj_genre.csv')\n",
    "df1['embedding'] = ['vggish'] * 40 + ['openl3'] * 40 + ['yamnet'] * 40 \n",
    "df2['embedding'] = ['vggish-lda'] * 40 + ['openl3-lda'] * 40 + ['yamnet-lda'] * 40 \n",
    "df3['embedding'] = ['vggish-lda-genre'] * 40 + ['openl3-lda-genre'] * 40 + ['yamnet-lda-genre'] * 40\n",
    "\n",
    "df = df1.append(df2).append(df3)\n",
    "df.to_csv('crossdataset_generalization_result_allcompare.csv', index=False)#\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('crossdataset_generalization_result_allcompare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('crossdataset_generalization_result_kernelize.csv')\n",
    "df2 = pd.read_csv('crossdataset_generalization_result_kernelLDA.csv')\n",
    "df3 = pd.read_csv('crossdataset_generalization_result_kernelLDA_genre.csv')\n",
    "df1['embedding'] = ['vggish-k'] * 40 + ['openl3-k'] * 40 + ['yamnet-k'] * 40 \n",
    "df2['embedding'] = ['vggish-klda'] * 40 + ['openl3-klda'] * 40 + ['yamnet-klda'] * 40 \n",
    "df3['embedding'] = ['vggish-klda-genre'] * 40 + ['openl3-klda-genre'] * 40 + ['yamnet-klda-genre'] * 40\n",
    "\n",
    "df = df1.append(df2).append(df3)\n",
    "df.to_csv('crossdataset_generalization_result_allcompare_kLDA.csv', index=False)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>instrument</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vggish</td>\n",
       "      <td>cello</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.924896</td>\n",
       "      <td>0.623731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vggish</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.434590</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.879935</td>\n",
       "      <td>0.534471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vggish</td>\n",
       "      <td>flute</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.309764</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.859544</td>\n",
       "      <td>0.891979</td>\n",
       "      <td>0.612665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vggish</td>\n",
       "      <td>guitar</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.662005</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.934091</td>\n",
       "      <td>0.825266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vggish</td>\n",
       "      <td>organ</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.647303</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.956881</td>\n",
       "      <td>0.706318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>piano</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.263982</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.382496</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.771309</td>\n",
       "      <td>0.840771</td>\n",
       "      <td>0.603728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>saxophone</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.263305</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.370809</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.808523</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>0.346632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>trumpet</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.510067</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.868547</td>\n",
       "      <td>0.899384</td>\n",
       "      <td>0.576749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>violin</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.297806</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.411255</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.828357</td>\n",
       "      <td>0.384510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>voice</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.588050</td>\n",
       "      <td>0.979058</td>\n",
       "      <td>0.734774</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.918968</td>\n",
       "      <td>0.986040</td>\n",
       "      <td>0.919020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             embedding instrument train_set test_set  precision    recall  \\\n",
       "0               vggish      cello     irmas    irmas   0.296296  0.851064   \n",
       "1               vggish   clarinet     irmas    irmas   0.302469  0.771654   \n",
       "2               vggish      flute     irmas    irmas   0.309764  0.760331   \n",
       "3               vggish     guitar     irmas    irmas   0.662005  0.820809   \n",
       "4               vggish      organ     irmas    irmas   0.506494  0.896552   \n",
       "..                 ...        ...       ...      ...        ...       ...   \n",
       "115  yamnet-klda-genre      piano   openmic    irmas   0.263982  0.694118   \n",
       "116  yamnet-klda-genre  saxophone   openmic    irmas   0.263305  0.626667   \n",
       "117  yamnet-klda-genre    trumpet   openmic    irmas   0.383838  0.760000   \n",
       "118  yamnet-klda-genre     violin   openmic    irmas   0.297806  0.664336   \n",
       "119  yamnet-klda-genre      voice   openmic    irmas   0.588050  0.979058   \n",
       "\n",
       "     f1-score  support  accuracy   roc_auc        ap  \n",
       "0    0.439560     94.0  0.877551  0.924896  0.623731  \n",
       "1    0.434590    127.0  0.846939  0.879935  0.534471  \n",
       "2    0.440191    121.0  0.859544  0.891979  0.612665  \n",
       "3    0.732903    346.0  0.875750  0.934091  0.825266  \n",
       "4    0.647303    174.0  0.897959  0.956881  0.706318  \n",
       "..        ...      ...       ...       ...       ...  \n",
       "115  0.382496    170.0  0.771309  0.840771  0.603728  \n",
       "116  0.370809    150.0  0.808523  0.817493  0.346632  \n",
       "117  0.510067    150.0  0.868547  0.899384  0.576749  \n",
       "118  0.411255    143.0  0.836735  0.828357  0.384510  \n",
       "119  0.734774    191.0  0.918968  0.986040  0.919020  \n",
       "\n",
       "[720 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df0.append(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>instrument</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vggish</td>\n",
       "      <td>cello</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.924896</td>\n",
       "      <td>0.623731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vggish</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.434590</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.879935</td>\n",
       "      <td>0.534471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vggish</td>\n",
       "      <td>flute</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.309764</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.859544</td>\n",
       "      <td>0.891979</td>\n",
       "      <td>0.612665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vggish</td>\n",
       "      <td>guitar</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.662005</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.934091</td>\n",
       "      <td>0.825266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vggish</td>\n",
       "      <td>organ</td>\n",
       "      <td>irmas</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.647303</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.956881</td>\n",
       "      <td>0.706318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>piano</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.263982</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.382496</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.771309</td>\n",
       "      <td>0.840771</td>\n",
       "      <td>0.603728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>saxophone</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.263305</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.370809</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.808523</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>0.346632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>trumpet</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.510067</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.868547</td>\n",
       "      <td>0.899384</td>\n",
       "      <td>0.576749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>violin</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.297806</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.411255</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.828357</td>\n",
       "      <td>0.384510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>yamnet-klda-genre</td>\n",
       "      <td>voice</td>\n",
       "      <td>openmic</td>\n",
       "      <td>irmas</td>\n",
       "      <td>0.588050</td>\n",
       "      <td>0.979058</td>\n",
       "      <td>0.734774</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.918968</td>\n",
       "      <td>0.986040</td>\n",
       "      <td>0.919020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             embedding instrument train_set test_set  precision    recall  \\\n",
       "0               vggish      cello     irmas    irmas   0.296296  0.851064   \n",
       "1               vggish   clarinet     irmas    irmas   0.302469  0.771654   \n",
       "2               vggish      flute     irmas    irmas   0.309764  0.760331   \n",
       "3               vggish     guitar     irmas    irmas   0.662005  0.820809   \n",
       "4               vggish      organ     irmas    irmas   0.506494  0.896552   \n",
       "..                 ...        ...       ...      ...        ...       ...   \n",
       "115  yamnet-klda-genre      piano   openmic    irmas   0.263982  0.694118   \n",
       "116  yamnet-klda-genre  saxophone   openmic    irmas   0.263305  0.626667   \n",
       "117  yamnet-klda-genre    trumpet   openmic    irmas   0.383838  0.760000   \n",
       "118  yamnet-klda-genre     violin   openmic    irmas   0.297806  0.664336   \n",
       "119  yamnet-klda-genre      voice   openmic    irmas   0.588050  0.979058   \n",
       "\n",
       "     f1-score  support  accuracy   roc_auc        ap  \n",
       "0    0.439560     94.0  0.877551  0.924896  0.623731  \n",
       "1    0.434590    127.0  0.846939  0.879935  0.534471  \n",
       "2    0.440191    121.0  0.859544  0.891979  0.612665  \n",
       "3    0.732903    346.0  0.875750  0.934091  0.825266  \n",
       "4    0.647303    174.0  0.897959  0.956881  0.706318  \n",
       "..        ...      ...       ...       ...       ...  \n",
       "115  0.382496    170.0  0.771309  0.840771  0.603728  \n",
       "116  0.370809    150.0  0.808523  0.817493  0.346632  \n",
       "117  0.510067    150.0  0.868547  0.899384  0.576749  \n",
       "118  0.411255    143.0  0.836735  0.828357  0.384510  \n",
       "119  0.734774    191.0  0.918968  0.986040  0.919020  \n",
       "\n",
       "[720 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('crossdataset_generalization_result_allcompare.csv', index=False)#\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "621.778px",
    "left": "21px",
    "top": "111.139px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
